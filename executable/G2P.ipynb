{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Paper: https://arxiv.org/abs/1506.00196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:54.925299Z",
     "start_time": "2017-04-24T23:32:54.921876+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:54.966569Z",
     "start_time": "2017-04-24T23:32:54.927613+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein  # to compute phoneme error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:55.975071Z",
     "start_time": "2017-04-24T23:32:54.968879+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "import torchtext.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:55.989639Z",
     "start_time": "2017-04-24T23:32:55.977844+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': '../data/cmudict/',\n",
    "    'epochs': 50,\n",
    "    'batch_size': 100,\n",
    "    'max_len': 20,\n",
    "    'beam_size': 3,\n",
    "    'd_embed': 500,\n",
    "    'd_hidden': 500,\n",
    "    'attention': True,\n",
    "    'log_every': 100,\n",
    "    'lr': 0.007,\n",
    "    'lr_decay': 0.5,\n",
    "    'lr_min': 1e-5,  # stop when lr is too low\n",
    "    'n_bad_loss': 5,  # number of bad loss before decaying\n",
    "    'clip': 2.3,  # clip gradient\n",
    "    'cuda': True,\n",
    "    'seed': 5,\n",
    "    'intermediate_path': '../intermediate/g2p/',\n",
    "}\n",
    "args = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.076833Z",
     "start_time": "2017-04-24T23:32:55.992015+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.makedirs(args.intermediate_path)\n",
    "if not os.path.isdir(args.data_path):\n",
    "    URL = \"https://github.com/cmusphinx/cmudict/archive/master.zip\"\n",
    "    !wget $URL -O ../data/cmudict.zip\n",
    "    !unzip ../data/cmudict.zip -d ../data/\n",
    "    !mv ../data/cmudict-master $args.data_path\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.112244Z",
     "start_time": "2017-04-24T23:32:56.079605+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_embed, d_hidden):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.lstm = nn.LSTMCell(d_embed, d_hidden)\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "    def forward(self, x_seq, cuda=False):\n",
    "        o = []\n",
    "        # dim(e_seq): len_seq x batch_size x d_embed\n",
    "        e_seq = self.embedding(x_seq)\n",
    "        tt = torch.cuda if cuda else torch\n",
    "        h = Variable(tt.FloatTensor(e_seq.size(1), self.d_hidden).zero_())\n",
    "        c = Variable(tt.FloatTensor(e_seq.size(1), self.d_hidden).zero_())\n",
    "        for e in e_seq.chunk(e_seq.size(0), 0):\n",
    "            e = e.squeeze(0)\n",
    "            h, c = self.lstm(e, (h, c))\n",
    "            o.append(h)\n",
    "        return torch.stack(o, 0), h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.154214Z",
     "start_time": "2017-04-24T23:32:56.114622+09:00"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# based on https://github.com/OpenNMT/OpenNMT-py\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"Dot global attention from https://arxiv.org/abs/1508.04025\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear = nn.Linear(dim*2, dim, bias=False)\n",
    "        \n",
    "    def forward(self, x, context=None):\n",
    "        if context is None:\n",
    "            return x\n",
    "        assert x.size(0) == context.size(0)  # x: batch x dim\n",
    "        assert x.size(1) == context.size(2)  # context: batch x seq x dim\n",
    "        attn = F.softmax(context.bmm(x.unsqueeze(2)).squeeze(2))\n",
    "        weighted_context = attn.unsqueeze(1).bmm(context).squeeze(1)\n",
    "        o = self.linear(torch.cat((x, weighted_context), 1))\n",
    "        return F.tanh(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.202671Z",
     "start_time": "2017-04-24T23:32:56.156569+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, d_embed, d_hidden):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.lstm = nn.LSTMCell(d_embed, d_hidden)\n",
    "        self.linear = nn.Linear(d_hidden, vocab_size)\n",
    "        self.attn = Attention(d_hidden)\n",
    "\n",
    "    def forward(self, x_seq, h, c, context=None):\n",
    "        o = []\n",
    "        e_seq = self.embedding(x_seq)\n",
    "        for e in e_seq.chunk(e_seq.size(0), 0):\n",
    "            e = e.squeeze(0)\n",
    "            h, c = self.lstm(e, (h, c))\n",
    "            o.append(self.attn(h, context))\n",
    "        o = torch.stack(o, 0)\n",
    "        o = self.linear(o.view(-1, h.size(1)))\n",
    "        return F.log_softmax(o).view(x_seq.size(0), -1, o.size(1)), h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.244503Z",
     "start_time": "2017-04-24T23:32:56.205014+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class G2P(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(G2P, self).__init__()\n",
    "        self.encoder = Encoder(config.g_size, config.d_embed,\n",
    "                               config.d_hidden)\n",
    "        self.decoder = Decoder(config.p_size, config.d_embed,\n",
    "                               config.d_hidden)\n",
    "        self.config = config\n",
    "        \n",
    "    def forward(self, g_seq, p_seq=None):\n",
    "        o, h, c = self.encoder(g_seq, self.config.cuda)\n",
    "        context = o.t() if self.config.attention else None\n",
    "        if p_seq is not None:  # not generate\n",
    "            return self.decoder(p_seq, h, c, context)\n",
    "        else:  # start with <os> -> 1\n",
    "            assert g_seq.size(1) == 1  # make sure batch_size = 1\n",
    "            return self._generate(h, c, context)\n",
    "        \n",
    "    def _generate(self, h, c, context):\n",
    "        beam = Beam(self.config.beam_size, cuda=self.config.cuda)\n",
    "        h = h.expand(beam.size, h.size(1))\n",
    "        c = c.expand(beam.size, c.size(1))\n",
    "        for i in range(self.config.max_len):  # max_len = 20\n",
    "            x = beam.get_current_state()  # beam to batch\n",
    "            o, h, c = self.decoder(Variable(x.unsqueeze(0)), h, c, context)\n",
    "            if beam.advance(o.data.squeeze(0)):\n",
    "                break\n",
    "            h.data.copy_(h.data.index_select(0, beam.get_current_origin()))\n",
    "            c.data.copy_(c.data.index_select(0, beam.get_current_origin()))\n",
    "        tt = torch.cuda if self.config.cuda else torch\n",
    "        return Variable(tt.LongTensor(beam.get_hyp(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.317700Z",
     "start_time": "2017-04-24T23:32:56.246853+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Code borrowed from PyTorch OpenNMT\n",
    "# https://github.com/OpenNMT/OpenNMT-py/\n",
    "# https://github.com/MaximumEntropy/Seq2Seq-PyTorch/\n",
    "\n",
    "class Beam(object):\n",
    "    \"\"\"Ordered beam of candidate outputs.\"\"\"\n",
    "\n",
    "    def __init__(self, size, pad=1, bos=2, eos=3, cuda=False):\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        self.size = size\n",
    "        self.done = False\n",
    "        self.pad = pad\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "        self.tt = torch.cuda if cuda else torch\n",
    "\n",
    "        # The score for each translation on the beam.\n",
    "        self.scores = self.tt.FloatTensor(size).zero_()\n",
    "\n",
    "        # The backpointers at each time-step.\n",
    "        self.prevKs = []\n",
    "\n",
    "        # The outputs at each time-step.\n",
    "        self.nextYs = [self.tt.LongTensor(size).fill_(self.pad)]\n",
    "        self.nextYs[0][0] = self.bos\n",
    "\n",
    "    # Get the outputs for the current timestep.\n",
    "    def get_current_state(self):\n",
    "        \"\"\"Get state of beam.\"\"\"\n",
    "        return self.nextYs[-1]\n",
    "\n",
    "    # Get the backpointers for the current timestep.\n",
    "    def get_current_origin(self):\n",
    "        \"\"\"Get the backpointer to the beam at this step.\"\"\"\n",
    "        return self.prevKs[-1]\n",
    "\n",
    "    def advance(self, workd_lk):\n",
    "        \"\"\"Advance the beam.\"\"\"\n",
    "        num_words = workd_lk.size(1)\n",
    "\n",
    "        # Sum the previous scores.\n",
    "        if len(self.prevKs) > 0:\n",
    "            beam_lk = workd_lk + self.scores.unsqueeze(1).expand_as(workd_lk)\n",
    "        else:\n",
    "            beam_lk = workd_lk[0]\n",
    "\n",
    "        flat_beam_lk = beam_lk.view(-1)\n",
    "\n",
    "        bestScores, bestScoresId = flat_beam_lk.topk(self.size, 0,\n",
    "                                                     True, True)\n",
    "        self.scores = bestScores\n",
    "\n",
    "        # bestScoresId is flattened beam x word array, so calculate which\n",
    "        # word and beam each score came from\n",
    "        prev_k = bestScoresId / num_words\n",
    "        self.prevKs.append(prev_k)\n",
    "        self.nextYs.append(bestScoresId - prev_k * num_words)\n",
    "        # End condition is when top-of-beam is EOS.\n",
    "        if self.nextYs[-1][0] == self.eos:\n",
    "            self.done = True\n",
    "        return self.done\n",
    "\n",
    "    def get_hyp(self, k):\n",
    "        \"\"\"Get hypotheses.\"\"\"\n",
    "        hyp = []\n",
    "        # print(len(self.prevKs), len(self.nextYs), len(self.attn))\n",
    "        for j in range(len(self.prevKs) - 1, -1, -1):\n",
    "            hyp.append(self.nextYs[j + 1][k])\n",
    "            k = self.prevKs[j][k]\n",
    "        return hyp[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.366423Z",
     "start_time": "2017-04-24T23:32:56.319887+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CMUDict(data.Dataset):\n",
    "\n",
    "    def __init__(self, data_lines, g_field, p_field):\n",
    "        fields = [('grapheme', g_field), ('phoneme', p_field)]\n",
    "        examples = []  # maybe ignore '...-1' grapheme\n",
    "        for line in data_lines:\n",
    "            grapheme, phoneme = line.split(maxsplit=1)\n",
    "            examples.append(data.Example.fromlist([grapheme, phoneme],\n",
    "                                                  fields))\n",
    "        self.sort_key = lambda x: len(x.grapheme)\n",
    "        super(CMUDict, self).__init__(examples, fields)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, path, g_field, p_field, seed=None):\n",
    "        import random\n",
    "        \n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        with open(path) as f:\n",
    "            lines = f.readlines()\n",
    "        random.shuffle(lines)\n",
    "        train_lines, val_lines, test_lines = [], [], []\n",
    "        for i, line in enumerate(lines):\n",
    "            if i % 20 == 0:\n",
    "                val_lines.append(line)\n",
    "            elif i % 20 < 3:\n",
    "                test_lines.append(line)\n",
    "            else:\n",
    "                train_lines.append(line)\n",
    "        train_data = cls(train_lines, g_field, p_field)\n",
    "        val_data = cls(val_lines, g_field, p_field)\n",
    "        test_data = cls(test_lines, g_field, p_field)\n",
    "        return (train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.414698Z",
     "start_time": "2017-04-24T23:32:56.368711+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Code borrowed from https://github.com/SeanNaren/deepspeech.pytorch\n",
    "\n",
    "def phoneme_error_rate(p_seq1, p_seq2):\n",
    "    p_vocab = set(p_seq1 + p_seq2)\n",
    "    p2c = dict(zip(p_vocab, range(len(p_vocab))))\n",
    "    c_seq1 = [chr(p2c[p]) for p in p_seq1]\n",
    "    c_seq2 = [chr(p2c[p]) for p in p_seq2]\n",
    "    return Levenshtein.distance(''.join(c_seq1),\n",
    "                                ''.join(c_seq2)) / len(c_seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.453534Z",
     "start_time": "2017-04-24T23:32:56.417059+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr_decay):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.502586Z",
     "start_time": "2017-04-24T23:32:56.455962+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_iter, model, criterion, optimizer, epoch):\n",
    "    global iteration, n_total, train_loss, n_bad_loss\n",
    "    global init, best_val_loss, stop\n",
    "    \n",
    "    print(\"=> EPOCH {}\".format(epoch))\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:\n",
    "        iteration += 1\n",
    "        model.train()\n",
    "        \n",
    "        output, _, __ = model(batch.grapheme, batch.phoneme[:-1].detach())\n",
    "        target = batch.phoneme[1:]\n",
    "        loss = criterion(output.view(output.size(0) * output.size(1), -1),\n",
    "                         target.view(target.size(0) * target.size(1)))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), config.clip, 'inf')\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_total += batch.batch_size\n",
    "        train_loss += loss.data[0] * batch.batch_size\n",
    "        \n",
    "        if iteration % config.log_every == 0:\n",
    "            train_loss /= n_total\n",
    "            val_loss = validate(val_iter, model, criterion)\n",
    "            print(\"   % Time: {:5.0f} | Iteration: {:5} | Batch: {:4}/{}\"\n",
    "                  \" | Train loss: {:.4f} | Val loss: {:.4f}\"\n",
    "                  .format(time.time()-init, iteration, train_iter.iterations,\n",
    "                          len(train_iter), train_loss, val_loss))\n",
    "            \n",
    "            n_total = train_loss = 0\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                torch.save(model.state_dict(), config.best_model)\n",
    "            else:\n",
    "                n_bad_loss += 1\n",
    "            if n_bad_loss == config.n_bad_loss:\n",
    "                adjust_learning_rate(optimizer, config.lr_decay)\n",
    "                new_lr = optimizer.param_groups[0]['lr']\n",
    "                print(\"=> Adjust learning rate to: {}\".format(new_lr))\n",
    "                if new_lr < config.lr_min:\n",
    "                    stop = True\n",
    "                    break\n",
    "                n_bad_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.554170Z",
     "start_time": "2017-04-24T23:32:56.504939+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def validate(val_iter, model, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iter.init_epoch()\n",
    "    for batch in val_iter:\n",
    "        output, _, __ = model(batch.grapheme, batch.phoneme[:-1])\n",
    "        target = batch.phoneme[1:]\n",
    "        loss = criterion(output.squeeze(1), target.squeeze(1))\n",
    "        val_loss += loss.data[0] * batch.batch_size\n",
    "    return val_loss / len(val_iter.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.602569Z",
     "start_time": "2017-04-24T23:32:56.556800+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(test_iter, model, criterion):\n",
    "    model.eval()\n",
    "    test_iter.init_epoch()\n",
    "    test_per = test_wer = 0\n",
    "    for batch in test_iter:\n",
    "        output = model(batch.grapheme).data.tolist()\n",
    "        target = batch.phoneme[1:].squeeze(1).data.tolist()\n",
    "        # calculate per, wer here\n",
    "        per = phoneme_error_rate(output, target) \n",
    "        wer = int(output != target)\n",
    "        test_per += per  # batch_size = 1\n",
    "        test_wer += wer\n",
    "        \n",
    "    test_per = test_per / len(test_iter.dataset) * 100\n",
    "    test_wer = test_wer / len(test_iter.dataset) * 100\n",
    "    print(\"Phoneme error rate (PER): {:.2f}\\nWord error rate (WER): {:.2f}\"\n",
    "          .format(test_per, test_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.639727Z",
     "start_time": "2017-04-24T23:32:56.604946+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show(batch, model):\n",
    "    assert batch.batch_size == 1\n",
    "    g_field = batch.dataset.fields['grapheme']\n",
    "    p_field = batch.dataset.fields['phoneme']\n",
    "    prediction = model(batch.grapheme).data.tolist()[:-1]\n",
    "    grapheme = batch.grapheme.squeeze(1).data.tolist()[1:][::-1]\n",
    "    phoneme = batch.phoneme.squeeze(1).data.tolist()[1:-1]\n",
    "    print(\"> {}\\n= {}\\n< {}\\n\".format(\n",
    "        ''.join([g_field.vocab.itos[g] for g in grapheme]),\n",
    "        ' '.join([p_field.vocab.itos[p] for p in phoneme]),\n",
    "        ' '.join([p_field.vocab.itos[p] for p in prediction])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:32:56.681704Z",
     "start_time": "2017-04-24T23:32:56.642173+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g_field = data.Field(init_token='<s>',\n",
    "                     tokenize=(lambda x: list(x.split('(')[0])[::-1]))\n",
    "p_field = data.Field(init_token='<os>', eos_token='</os>',\n",
    "                     tokenize=(lambda x: x.split('#')[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:33:02.876140Z",
     "start_time": "2017-04-24T23:32:56.684170+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(args.data_path, 'cmudict.dict')\n",
    "train_data, val_data, test_data = CMUDict.splits(filepath, g_field, p_field,\n",
    "                                                 args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:33:04.772355Z",
     "start_time": "2017-04-24T23:33:02.878832+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g_field.build_vocab(train_data, val_data, test_data)\n",
    "p_field.build_vocab(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-24T14:33:04.780633Z",
     "start_time": "2017-04-24T23:33:04.774848+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "device = None if args.cuda else -1  # None is current gpu\n",
    "train_iter = data.BucketIterator(train_data, batch_size=args.batch_size,\n",
    "                                 repeat=False, device=device)\n",
    "val_iter = data.Iterator(val_data, batch_size=1,\n",
    "                         train=False, sort=False, device=device)\n",
    "test_iter = data.Iterator(test_data, batch_size=1,\n",
    "                          train=False, shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-04-24T14:33:02.719Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = args\n",
    "config.g_size = len(g_field.vocab)\n",
    "config.p_size = len(p_field.vocab)\n",
    "config.best_model = os.path.join(config.intermediate_path,\n",
    "                                 \"best_model_adagrad_attn.pth\")\n",
    "\n",
    "model = G2P(config)\n",
    "criterion = nn.NLLLoss()\n",
    "if config.cuda:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr)  # use Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-04-24T14:33:02.727Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1\n",
      "   % Time:   107 | Iteration:   100 | Batch:  100/1148 | Train loss: 1.2808 | Val loss: 0.8004\n"
     ]
    }
   ],
   "source": [
    "if 1 == 1:  # change to True to train\n",
    "    iteration = n_total = train_loss = n_bad_loss = 0\n",
    "    stop = False\n",
    "    best_val_loss = 10\n",
    "    init = time.time()\n",
    "    for epoch in range(1, config.epochs+1):\n",
    "        train(config, train_iter, model, criterion, optimizer, epoch)\n",
    "        if stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-04-24T14:33:02.734Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(config.best_model))\n",
    "test(test_iter, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-04-24T14:33:02.735Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_iter.init_epoch()\n",
    "for i, batch in enumerate(test_iter):\n",
    "    show(batch, model)\n",
    "    if i == 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
