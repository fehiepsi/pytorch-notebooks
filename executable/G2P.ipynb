{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Paper: https://arxiv.org/abs/1506.00196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:38.661989Z",
     "start_time": "2017-04-23T14:40:38.658800+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:38.695976Z",
     "start_time": "2017-04-23T14:40:38.664153+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Levenshtein  # to compute phoneme error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.697986Z",
     "start_time": "2017-04-23T14:40:38.698240+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "import torchtext.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.711523Z",
     "start_time": "2017-04-23T14:40:39.700435+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': '../data/cmudict/',\n",
    "    'epochs': 50,\n",
    "    'batch_size': 100,\n",
    "    'max_len': 20,\n",
    "    'beam_size': 3,\n",
    "    'd_embed': 500,\n",
    "    'd_hidden': 500,\n",
    "    'log_every': 100,\n",
    "    'lr': 0.007,\n",
    "    'lr_decay': 0.5,\n",
    "    'lr_min': 1e-6,  # stop when lr is too low\n",
    "    'n_bad_loss': 5,  # number of bad loss before decaying\n",
    "    'clip': 2.3,  # clip gradient\n",
    "    'cuda': True,\n",
    "    'seed': 5,\n",
    "    'intermediate_path': '../intermediate/g2p/',\n",
    "}\n",
    "args = argparse.Namespace(**parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.783799Z",
     "start_time": "2017-04-23T14:40:39.713764+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.makedirs(args.intermediate_path)\n",
    "if not os.path.isdir(args.data_path):\n",
    "    URL = \"https://github.com/cmusphinx/cmudict/archive/master.zip\"\n",
    "    !wget $URL -O ../data/cmudict.zip\n",
    "    !unzip ../data/cmudict.zip -d ../data/\n",
    "    !mv ../data/cmudict-master $args.data_path\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.817666Z",
     "start_time": "2017-04-23T14:40:39.786499+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_embed, d_hidden):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.lstm = nn.LSTMCell(d_embed, d_hidden)\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "    def forward(self, x_seq, cuda=False):\n",
    "        # dim(e_seq): len_seq x batch_size x d_embed\n",
    "        e_seq = self.embedding(x_seq)\n",
    "        tt = torch.cuda if config.cuda else torch\n",
    "        h = Variable(tt.FloatTensor(e_seq.size(1), self.d_hidden).zero_())\n",
    "        c = Variable(tt.FloatTensor(e_seq.size(1), self.d_hidden).zero_())\n",
    "        for e in e_seq.chunk(e_seq.size(0), 0):\n",
    "            e = e.squeeze(0)\n",
    "            h, c = self.lstm(e, (h, c))\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.870717Z",
     "start_time": "2017-04-23T14:40:39.819997+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, d_embed, d_hidden):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.lstm = nn.LSTMCell(d_embed, d_hidden)\n",
    "        self.linear = nn.Linear(d_hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x_seq, h, c):\n",
    "        o = []\n",
    "        e_seq = self.embedding(x_seq)\n",
    "        for e in e_seq.chunk(e_seq.size(0), 0):\n",
    "            e = e.squeeze(0)\n",
    "            h, c = self.lstm(e, (h, c))\n",
    "            o.append(h)\n",
    "        o = torch.stack(o, 0)\n",
    "        o = self.linear(o.view(-1, h.size(1)))\n",
    "        return F.log_softmax(o).view(x_seq.size(0), -1, o.size(1)), h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.903947Z",
     "start_time": "2017-04-23T14:40:39.873022+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class G2P(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(G2P, self).__init__()\n",
    "        self.encoder = Encoder(config.g_size, config.d_embed,\n",
    "                               config.d_hidden)\n",
    "        self.decoder = Decoder(config.p_size, config.d_embed,\n",
    "                               config.d_hidden)\n",
    "        self.config = config\n",
    "        \n",
    "    def forward(self, g_seq, p_seq=None):\n",
    "        h, c = self.encoder(g_seq, self.config.cuda)\n",
    "        if p_seq is not None:  # not generate\n",
    "            return self.decoder(p_seq, h, c)\n",
    "        else:  # start with <os> -> 1\n",
    "            assert g_seq.size(1) == 1  # make sure batch_size = 1\n",
    "            return self.generate(h, c)\n",
    "        \n",
    "    def generate(self, h, c):\n",
    "        beam = Beam(self.config.beam_size, cuda=self.config.cuda)\n",
    "        h = h.expand(beam.size, h.size(1))\n",
    "        c = c.expand(beam.size, c.size(1))\n",
    "        for i in range(self.config.max_len):  # max_len = 20\n",
    "            x = beam.get_current_state()  # beam to batch\n",
    "            o, h, c = self.decoder(Variable(x.unsqueeze(0)), h, c)\n",
    "            if beam.advance(o.data.squeeze(0)):\n",
    "                break\n",
    "            h.data.copy_(h.data.index_select(0, beam.get_current_origin()))\n",
    "            c.data.copy_(c.data.index_select(0, beam.get_current_origin()))\n",
    "        tt = torch.cuda if config.cuda else torch\n",
    "        return Variable(tt.LongTensor(beam.get_hyp(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:39.977279Z",
     "start_time": "2017-04-23T14:40:39.906496+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code borrowed from PyTorch OpenNMT\n",
    "# https://github.com/OpenNMT/OpenNMT-py/\n",
    "# https://github.com/MaximumEntropy/Seq2Seq-PyTorch/\n",
    "\n",
    "class Beam(object):\n",
    "    \"\"\"Ordered beam of candidate outputs.\"\"\"\n",
    "\n",
    "    def __init__(self, size, pad=1, bos=2, eos=3, cuda=False):\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        self.size = size\n",
    "        self.done = False\n",
    "        self.pad = pad\n",
    "        self.bos = bos\n",
    "        self.eos = eos\n",
    "        self.tt = torch.cuda if cuda else torch\n",
    "\n",
    "        # The score for each translation on the beam.\n",
    "        self.scores = self.tt.FloatTensor(size).zero_()\n",
    "\n",
    "        # The backpointers at each time-step.\n",
    "        self.prevKs = []\n",
    "\n",
    "        # The outputs at each time-step.\n",
    "        self.nextYs = [self.tt.LongTensor(size).fill_(self.pad)]\n",
    "        self.nextYs[0][0] = self.bos\n",
    "\n",
    "    # Get the outputs for the current timestep.\n",
    "    def get_current_state(self):\n",
    "        \"\"\"Get state of beam.\"\"\"\n",
    "        return self.nextYs[-1]\n",
    "\n",
    "    # Get the backpointers for the current timestep.\n",
    "    def get_current_origin(self):\n",
    "        \"\"\"Get the backpointer to the beam at this step.\"\"\"\n",
    "        return self.prevKs[-1]\n",
    "\n",
    "    def advance(self, workd_lk):\n",
    "        \"\"\"Advance the beam.\"\"\"\n",
    "        num_words = workd_lk.size(1)\n",
    "\n",
    "        # Sum the previous scores.\n",
    "        if len(self.prevKs) > 0:\n",
    "            beam_lk = workd_lk + self.scores.unsqueeze(1).expand_as(workd_lk)\n",
    "        else:\n",
    "            beam_lk = workd_lk[0]\n",
    "\n",
    "        flat_beam_lk = beam_lk.view(-1)\n",
    "\n",
    "        bestScores, bestScoresId = flat_beam_lk.topk(self.size, 0,\n",
    "                                                     True, True)\n",
    "        self.scores = bestScores\n",
    "\n",
    "        # bestScoresId is flattened beam x word array, so calculate which\n",
    "        # word and beam each score came from\n",
    "        prev_k = bestScoresId / num_words\n",
    "        self.prevKs.append(prev_k)\n",
    "        self.nextYs.append(bestScoresId - prev_k * num_words)\n",
    "        # End condition is when top-of-beam is EOS.\n",
    "        if self.nextYs[-1][0] == self.eos:\n",
    "            self.done = True\n",
    "        return self.done\n",
    "\n",
    "    def get_hyp(self, k):\n",
    "        \"\"\"Get hypotheses.\"\"\"\n",
    "        hyp = []\n",
    "        # print(len(self.prevKs), len(self.nextYs), len(self.attn))\n",
    "        for j in range(len(self.prevKs) - 1, -1, -1):\n",
    "            hyp.append(self.nextYs[j + 1][k])\n",
    "            k = self.prevKs[j][k]\n",
    "        return hyp[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.028322Z",
     "start_time": "2017-04-23T14:40:39.979765+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CMUDict(data.Dataset):\n",
    "\n",
    "    def __init__(self, data_lines, g_field, p_field):\n",
    "        fields = [('grapheme', g_field), ('phoneme', p_field)]\n",
    "        examples = []  # maybe ignore '...-1' grapheme\n",
    "        for line in data_lines:\n",
    "            grapheme, phoneme = line.split(maxsplit=1)\n",
    "            examples.append(data.Example.fromlist([grapheme, phoneme],\n",
    "                                                  fields))\n",
    "        self.sort_key = lambda x: len(x.grapheme)\n",
    "        super(CMUDict, self).__init__(examples, fields)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, path, g_field, p_field, seed=None):\n",
    "        import random\n",
    "        \n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        with open(path) as f:\n",
    "            lines = f.readlines()\n",
    "        random.shuffle(lines)\n",
    "        train_lines, val_lines, test_lines = [], [], []\n",
    "        for i, line in enumerate(lines):\n",
    "            if i % 20 == 0:\n",
    "                val_lines.append(line)\n",
    "            elif i % 20 < 3:\n",
    "                test_lines.append(line)\n",
    "            else:\n",
    "                train_lines.append(line)\n",
    "        train_data = cls(train_lines, g_field, p_field)\n",
    "        val_data = cls(val_lines, g_field, p_field)\n",
    "        test_data = cls(test_lines, g_field, p_field)\n",
    "        return (train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.076357Z",
     "start_time": "2017-04-23T14:40:40.030588+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code borrowed from https://github.com/SeanNaren/deepspeech.pytorch\n",
    "\n",
    "def phoneme_error_rate(p_seq1, p_seq2):\n",
    "    p_vocab = set(p_seq1 + p_seq2)\n",
    "    p2c = dict(zip(p_vocab, range(len(p_vocab))))\n",
    "    c_seq1 = [chr(p2c[p]) for p in p_seq1]\n",
    "    c_seq2 = [chr(p2c[p]) for p in p_seq2]\n",
    "    return Levenshtein.distance(''.join(c_seq1),\n",
    "                                ''.join(c_seq2)) / len(c_seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.111291Z",
     "start_time": "2017-04-23T14:40:40.078733+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr_decay):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= lr_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.161241Z",
     "start_time": "2017-04-23T14:40:40.113786+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_iter, model, criterion, optimizer, epoch):\n",
    "    global iteration, n_total, train_loss, n_bad_loss\n",
    "    global init, best_val_loss, stop\n",
    "    \n",
    "    print(\"=> EPOCH {}\".format(epoch))\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:\n",
    "        iteration += 1\n",
    "        model.train()\n",
    "        \n",
    "        output, _, __ = model(batch.grapheme, batch.phoneme[:-1].detach())\n",
    "        target = batch.phoneme[1:]\n",
    "        loss = criterion(output.view(output.size(0) * output.size(1), -1),\n",
    "                         target.view(target.size(0) * target.size(1)))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), config.clip, 'inf')\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_total += batch.batch_size\n",
    "        train_loss += loss.data[0] * batch.batch_size\n",
    "        \n",
    "        if iteration % config.log_every == 0:\n",
    "            train_loss /= n_total\n",
    "            val_loss = validate(val_iter, model, criterion)\n",
    "            print(\"   % Time: {:5.0f} | Iteration: {:5} | Batch: {:4}/{}\"\n",
    "                  \" | Train loss: {:.4f} | Val loss: {:.4f}\"\n",
    "                  .format(time.time()-init, iteration, train_iter.iterations,\n",
    "                          len(train_iter), train_loss, val_loss))\n",
    "            \n",
    "            n_total = train_loss = 0\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                n_bad_loss = 0\n",
    "                torch.save(model.state_dict(), config.best_model)\n",
    "            else:\n",
    "                n_bad_loss += 1\n",
    "            if n_bad_loss == config.n_bad_loss:\n",
    "                adjust_learning_rate(optimizer, config.lr_decay)\n",
    "                new_lr = optimizer.param_groups[0]['lr']\n",
    "                print(\"=> Adjust learning rate to: {}\".format(new_lr))\n",
    "                if new_lr < config.lr_min:\n",
    "                    stop = True\n",
    "                    break\n",
    "                n_bad_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.203432Z",
     "start_time": "2017-04-23T14:40:40.163609+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_iter, model, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_iter.init_epoch()\n",
    "    for batch in val_iter:\n",
    "        output, _, __ = model(batch.grapheme)\n",
    "        target = batch.phoneme[1:]\n",
    "        loss = criterion(output.squeeze(1), target.squeeze(1))\n",
    "        val_loss += loss.data[0] * batch.batch_size\n",
    "    return val_loss / len(val_iter.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.258544Z",
     "start_time": "2017-04-23T14:40:40.205861+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_iter, model, criterion):\n",
    "    model.eval()\n",
    "    test_iter.init_epoch()\n",
    "    test_per = test_wer = 0\n",
    "    for batch in test_iter:\n",
    "        output = model(batch.grapheme).data.tolist()\n",
    "        target = batch.phoneme[1:].squeeze(1).data.tolist()\n",
    "        # calculate per, wer here\n",
    "        per = phoneme_error_rate(output, target) \n",
    "        wer = int(output == target)\n",
    "        test_per += per  # batch_size = 1\n",
    "        test_wer += wer\n",
    "        \n",
    "    test_per = test_per / len(test_iter.dataset) * 100\n",
    "    test_wer = test_wer / len(test_iter.dataset) * 100\n",
    "    print(\"Phoneme error rate (PER): {:.2f}\\nWord error rate (WER): {:.2f}\"\n",
    "          .format(test_per, test_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T06:38:39.896438Z",
     "start_time": "2017-04-23T15:38:39.886117+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(batch, model):\n",
    "    assert batch.batch_size == 1\n",
    "    g_field = batch.dataset.fields['grapheme']\n",
    "    p_field = batch.dataset.fields['phoneme']\n",
    "    prediction = model(batch.grapheme).data.tolist()[:-1]\n",
    "    grapheme = batch.grapheme.squeeze(1).data.tolist()[1:][::-1]\n",
    "    phoneme = batch.phoneme.squeeze(1).data.tolist()[1:-1]\n",
    "    print(\"> {}\\n= {}\\n< {}\\n\".format(\n",
    "        ''.join([g_field.vocab.itos[g] for g in grapheme]),\n",
    "        ' '.join([p_field.vocab.itos[p] for p in phoneme]),\n",
    "        ' '.join([p_field.vocab.itos[p] for p in prediction])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:40.291725Z",
     "start_time": "2017-04-23T14:40:40.260999+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g_field = data.Field(init_token='<s>',\n",
    "                     tokenize=(lambda x: list(x.split('(')[0])[::-1]))\n",
    "p_field = data.Field(init_token='<os>', eos_token='</os>',\n",
    "                     tokenize=(lambda x: x.split('#')[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:46.580515Z",
     "start_time": "2017-04-23T14:40:40.294141+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(args.data_path, 'cmudict.dict')\n",
    "train_data, val_data, test_data = CMUDict.splits(filepath, g_field, p_field,\n",
    "                                                 args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:48.416671Z",
     "start_time": "2017-04-23T14:40:46.583422+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "g_field.build_vocab(train_data, val_data, test_data)\n",
    "p_field.build_vocab(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T06:40:12.208227Z",
     "start_time": "2017-04-23T15:40:12.199480+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = None if args.cuda else -1  # None is current gpu\n",
    "train_iter = data.BucketIterator(train_data, batch_size=args.batch_size,\n",
    "                                 repeat=False, device=device)\n",
    "val_iter = data.Iterator(val_data, batch_size=1,\n",
    "                         train=False, device=device)\n",
    "test_iter = data.Iterator(test_data, batch_size=1,\n",
    "                          train=False, shuffle=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:50.800000Z",
     "start_time": "2017-04-23T14:40:48.427722+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = args\n",
    "config.g_size = len(g_field.vocab)\n",
    "config.p_size = len(p_field.vocab)\n",
    "config.best_model = os.path.join(config.intermediate_path,\n",
    "                                 \"best_model.pth\")\n",
    "\n",
    "model = G2P(config)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)  # use AdaGrad\n",
    "if config.cuda:\n",
    "    model.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:40:50.809083Z",
     "start_time": "2017-04-23T14:40:50.802685+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if 1 == 0:  # change to True to train\n",
    "    iteration = n_total = train_loss = n_bad_loss = 0\n",
    "    stop = False\n",
    "    best_val_loss = 10\n",
    "    init = time.time()\n",
    "    for epoch in range(1, config.epochs+1):\n",
    "        train(config, train_iter, model, criterion, optimizer, epoch)\n",
    "        if stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T05:44:31.262833Z",
     "start_time": "2017-04-23T14:40:50.811221+09:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme error rate (PER): 13.11\n",
      "Word error rate (WER): 50.89\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.best_model))\n",
    "test(test_iter, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T06:40:19.759192Z",
     "start_time": "2017-04-23T15:40:19.540982+09:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> povich\n",
      "= P OW1 V IH0 CH\n",
      "< P AA1 V IH0 CH\n",
      "\n",
      "> grismer\n",
      "= G ER1 IH0 Z AH0 M ER0\n",
      "< G R IH1 S M ER0\n",
      "\n",
      "> sousa's\n",
      "= S UW1 Z AH0 Z\n",
      "< S UW1 Z AH0 Z\n",
      "\n",
      "> offield\n",
      "= AA1 F IY2 L D\n",
      "< AO1 F IY0 L D\n",
      "\n",
      "> austrian\n",
      "= AO1 S T R IY0 AH0 N\n",
      "< AO1 S T R IY0 AH0 N\n",
      "\n",
      "> gallbladder\n",
      "= G AO1 L B L AE2 D ER0\n",
      "< G AE1 L B L D ER0 D\n",
      "\n",
      "> wind's\n",
      "= W IH1 N D Z\n",
      "< W AY1 N D Z\n",
      "\n",
      "> oshel\n",
      "= AA1 SH AH0 L\n",
      "< AA1 SH AH0 L\n",
      "\n",
      "> danelle\n",
      "= D AH0 N EH1 L\n",
      "< D AE1 N AH0 L\n",
      "\n",
      "> howat\n",
      "= HH AW1 AH0 T\n",
      "< HH AW1 AH0 T\n",
      "\n",
      "> szoke\n",
      "= SH OW1 K\n",
      "< SH OW1 K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_iter.init_epoch()\n",
    "for i, batch in enumerate(test_iter):\n",
    "    show(batch, model)\n",
    "    if i == 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
