{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Paper: https://arxiv.org/abs/1506.00196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:39.236336Z",
     "start_time": "2017-04-22T02:00:39.233397+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.232622Z",
     "start_time": "2017-04-22T02:00:39.238603+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "import torchtext.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.238678Z",
     "start_time": "2017-04-22T02:00:40.235318+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from beam_search import Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.312810Z",
     "start_time": "2017-04-22T02:00:40.241050+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': '../data/cmudict/',\n",
    "    'epochs': 1,  # default: 50\n",
    "    'batch_size': 100,\n",
    "    'd_embed': 500,\n",
    "    'd_hidden': 500,\n",
    "    'n_layers': 1,  # default: 2, to be implemented\n",
    "    'log_every': 100,\n",
    "    'lr': 0.007,\n",
    "    'lr_decay_by': 0.5,\n",
    "    'lr_decay_every': 5,  # iterations\n",
    "    'optim': 'adagrad',  # sgd\n",
    "    'clip': 2.3,  # torch.nn.utils.clip_grad_norm(parameters, clip, 'inf')\n",
    "    'val_every': 100,\n",
    "    'cuda': True,\n",
    "    'seed': 5,\n",
    "    'intermediate_path': '../intermediate/g2p/',\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "args.gpu = None if args.cuda else -1  # None is current gpu\n",
    "\n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.makedirs(args.intermediate_path)\n",
    "if not os.path.isdir(args.data_path):\n",
    "    URL = \"https://github.com/cmusphinx/cmudict/archive/master.zip\"\n",
    "    !wget $URL -O ../data/cmudict.zip\n",
    "    !unzip ../data/cmudict.zip -d ../data/\n",
    "    !mv ../data/cmudict-master $args.data_path\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.352542Z",
     "start_time": "2017-04-22T02:00:40.315318+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, d_embed, d_hidden):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.lstm = nn.LSTMCell(d_embed, d_hidden)\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "    def forward(self, x_seq):  # dim(e_seq): len_seq x batch_size x d_embed\n",
    "        e_seq = self.embedding(x_seq)\n",
    "        h = Variable(torch.zeros(e_seq.size(1), self.d_hidden))\n",
    "        c = Variable(torch.zeros(e_seq.size(1), self.d_hidden))\n",
    "        for e in e_seq.chunk(e_seq.size(0), 1):\n",
    "            e = e.squeeze(0)\n",
    "            h, c = self.lstm(e, (h, c))\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.405520Z",
     "start_time": "2017-04-22T02:00:40.354732+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, d_embed, d_hidden):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.lstm = nn.LSTMCell(d_embed, d_hidden)\n",
    "        self.linear = nn.Linear(d_hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x_seq, h, c):\n",
    "        o = []\n",
    "        e_seq = self.embedding(x_seq)\n",
    "        for e in e_seq.chunk(e_seq.size(0), 0):\n",
    "            e = e.squeeze(0)\n",
    "            h, c = self.lstm(e, (h, c))\n",
    "            o.append(h)\n",
    "        o = torch.stack(o, 0)\n",
    "        o = self.linear(o.view(-1, h.size(1)))\n",
    "        return F.log_softmax(o).view(x_seq.size(0), -1, o.size(1)), h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.437076Z",
     "start_time": "2017-04-22T02:00:40.407834+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class G2P(nn.Module):\n",
    "    \n",
    "    def __init__(self, g_size, p_size, d_embed, d_hidden):\n",
    "        super(G2P, self).__init__()\n",
    "        self.encoder = Encoder(g_size, d_embed, d_hidden)\n",
    "        self.decoder = Decoder(p_size, d_embed, d_hidden)\n",
    "        \n",
    "    def forward(self, g_seq, p_seq=None, max_len=0):\n",
    "        h, c = self.encoder(g_seq)\n",
    "        if p_seq is not None:  # not generate\n",
    "            return self.decoder(p_seq[:-1], h, c)\n",
    "        else:  # start with <os> -> 1\n",
    "            assert g_seq.size(1) == 1  # make sure batch_size = 1\n",
    "            return self.generate(h, c, max_len=max_len)\n",
    "        \n",
    "    def generate(self, h, c, max_len):\n",
    "        beam = Beam(args.beam_size, cuda=args.cuda)\n",
    "        h = h.expand(beam.size, h.size(1))\n",
    "        c = c.expand(beam.size, c.size(1))\n",
    "        for i in range(max_len):  # max_len = 20\n",
    "            x = beam.get_current_state()  # beam to batch\n",
    "            o, h, c = self.decoder(Variable(x.unsqueeze(0)), h, c)\n",
    "            if beam.advance(o.data.squeeze(0)):\n",
    "                break\n",
    "            h.data.copy_(h.data.index_select(0, beam.get_current_origin()))\n",
    "            c.data.copy_(c.data.index_select(0, beam.get_current_origin()))\n",
    "        return beam.get_hyp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.496650Z",
     "start_time": "2017-04-22T02:00:40.439489+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CMUDict(data.Dataset):\n",
    "\n",
    "    def __init__(self, data_lines, g_field, p_field):\n",
    "        fields = [('grapheme', g_field), ('phoneme', p_field)]\n",
    "        examples = []\n",
    "        for line in data_lines:\n",
    "            grapheme, phoneme = line.split(maxsplit=1)\n",
    "            examples.append(data.Example.fromlist([grapheme, phoneme],\n",
    "                                                  fields))\n",
    "        super(CMUDict, self).__init__(examples, fields)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, path, g_field, p_field, seed=None):\n",
    "        import random\n",
    "        \n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        with open(path) as f:\n",
    "            lines = f.readlines()\n",
    "        random.shuffle(lines)\n",
    "        train_lines, val_lines, test_lines = [], [], []\n",
    "        for i, line in enumerate(lines):\n",
    "            if i % 20 == 0:\n",
    "                val_lines.append(line)\n",
    "            elif i % 20 < 3:\n",
    "                test_lines.append(line)\n",
    "            else:\n",
    "                train_lines.append(line)\n",
    "        train_data = cls(train_lines, g_field, p_field)\n",
    "        val_data = cls(val_lines, g_field, p_field)\n",
    "        test_data = cls(test_lines, g_field, p_field)\n",
    "        return (train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.544201Z",
     "start_time": "2017-04-22T02:00:40.498994+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(args, epoch):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:40.580536Z",
     "start_time": "2017-04-22T02:00:40.546704+09:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_field = data.Field(init_token='<s>',\n",
    "                     tokenize=(lambda x: list(x.split('(')[0])[::-1]))\n",
    "p_field = data.Field(init_token='<os>', eos_token='</os>',\n",
    "                     tokenize=(lambda x: x.split('#')[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:46.965765Z",
     "start_time": "2017-04-22T02:00:40.582947+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(args.data_path, 'cmudict.dict')\n",
    "train_data, val_data, test_data = CMUDict.splits(filepath, g_field, p_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:48.826551Z",
     "start_time": "2017-04-22T02:00:46.968397+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_field.build_vocab(train_data, val_data, test_data)\n",
    "p_field.build_vocab(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:48.833378Z",
     "start_time": "2017-04-22T02:00:48.829479+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), batch_size=args.batch_size,\n",
    "    device=args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:51.196050Z",
     "start_time": "2017-04-22T02:00:48.835947+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_size = len(g_field.vocab)\n",
    "p_size = len(p_field.vocab)\n",
    "model = G2P(g_size, p_size, args.d_embed, args.d_hidden)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=args.lr)\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T17:00:51.202097Z",
     "start_time": "2017-04-22T02:00:51.198795+09:00"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs+1):\n",
    "    train(args, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
