{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intermediate_path = os.path.join(\"..\", \"intermediate\", \"gan\")\n",
    "if not os.path.exists(intermediate_path):\n",
    "    os.makedirs(intermediate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "epochs = 100\n",
    "Z_dim = 100\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]\n",
    "    xavier_stddev = 1. / np.sqrt((in_dim+out_dim) / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev,\n",
    "                    requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "Whx = xavier_init(size=[h_dim, X_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def G(z):\n",
    "    h = F.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = F.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = F.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    y = F.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    for p in params:\n",
    "        p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    mnist.MNIST('../data', train=True, download=True,\n",
    "                transform=transforms.ToTensor()),\n",
    "    batch_size=mb_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    start = time.time()\n",
    "    \n",
    "    for i, (X, _) in enumerate(train_loader):\n",
    "        ones_label = Variable(torch.ones(X.size(0)))\n",
    "        zeros_label = Variable(torch.zeros(X.size(0)))\n",
    "        X = X.view(-1, 784)\n",
    "        X = Variable(X)\n",
    "        # Sample data\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        \n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        D_loss_real = F.binary_cross_entropy(D_real, ones_label)\n",
    "        D_loss_fake = F.binary_cross_entropy(D_fake, zeros_label)\n",
    "        \n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        \n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "        reset_grad()\n",
    "        \n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        G_sample = G(z)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        G_loss = F.binary_cross_entropy(D_fake, ones_label)\n",
    "        \n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "        reset_grad()\n",
    "        \n",
    "        D_losses.add(D_loss.data.cpu()[0] * X.size(0), X.size(0))\n",
    "        G_losses.add(G_loss.data.cpu()[0] * X.size(0), X.size(0))\n",
    "        \n",
    "    print(\"   * EPOCH {} | Time: {}s | D_loss: {:.4f} | G_loss: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start),\n",
    "                  D_losses.value()[0],\n",
    "                  G_losses.value()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples, epoch):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis(\"off\")\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "        plt.imshow(sample.reshape(28, 28), cmap=\"Greys_r\")\n",
    "\n",
    "    out_path = os.path.join(intermediate_path, \"out\")\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    out_filepath = os.path.join(out_path, \n",
    "                                \"{}.png\".format(str(epoch).zfill(3)))\n",
    "    plt.savefig(out_filepath, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   * EPOCH 1 | Time: 25s | D_loss: 0.0885 | G_loss: 5.3372\n",
      "   * EPOCH 2 | Time: 26s | D_loss: 0.0639 | G_loss: 5.1707\n",
      "   * EPOCH 3 | Time: 25s | D_loss: 0.1065 | G_loss: 4.5663\n",
      "   * EPOCH 4 | Time: 25s | D_loss: 0.2214 | G_loss: 4.6510\n",
      "   * EPOCH 5 | Time: 26s | D_loss: 0.3088 | G_loss: 4.1979\n",
      "   * EPOCH 6 | Time: 25s | D_loss: 0.4808 | G_loss: 3.7872\n",
      "   * EPOCH 7 | Time: 25s | D_loss: 0.5365 | G_loss: 3.1798\n",
      "   * EPOCH 8 | Time: 26s | D_loss: 0.5744 | G_loss: 3.1267\n",
      "   * EPOCH 9 | Time: 25s | D_loss: 0.6274 | G_loss: 2.9110\n",
      "   * EPOCH 10 | Time: 25s | D_loss: 0.6818 | G_loss: 2.7613\n",
      "   * EPOCH 11 | Time: 25s | D_loss: 0.6946 | G_loss: 2.6511\n",
      "   * EPOCH 12 | Time: 26s | D_loss: 0.7201 | G_loss: 2.7746\n",
      "   * EPOCH 13 | Time: 25s | D_loss: 0.7558 | G_loss: 2.6204\n",
      "   * EPOCH 14 | Time: 25s | D_loss: 0.7741 | G_loss: 2.3711\n",
      "   * EPOCH 15 | Time: 25s | D_loss: 0.7586 | G_loss: 2.2646\n",
      "   * EPOCH 16 | Time: 26s | D_loss: 0.7686 | G_loss: 2.1683\n",
      "   * EPOCH 17 | Time: 26s | D_loss: 0.7824 | G_loss: 2.1378\n",
      "   * EPOCH 18 | Time: 26s | D_loss: 0.7918 | G_loss: 2.1628\n",
      "   * EPOCH 19 | Time: 26s | D_loss: 0.7763 | G_loss: 2.0816\n",
      "   * EPOCH 20 | Time: 27s | D_loss: 0.8013 | G_loss: 1.9879\n",
      "   * EPOCH 21 | Time: 27s | D_loss: 0.8011 | G_loss: 2.0188\n",
      "   * EPOCH 22 | Time: 28s | D_loss: 0.8214 | G_loss: 1.9092\n",
      "   * EPOCH 23 | Time: 29s | D_loss: 0.8271 | G_loss: 1.9075\n",
      "   * EPOCH 24 | Time: 30s | D_loss: 0.8330 | G_loss: 1.8905\n",
      "   * EPOCH 25 | Time: 30s | D_loss: 0.8387 | G_loss: 1.8859\n",
      "   * EPOCH 26 | Time: 31s | D_loss: 0.8488 | G_loss: 1.7896\n",
      "   * EPOCH 27 | Time: 32s | D_loss: 0.8487 | G_loss: 1.8290\n",
      "   * EPOCH 28 | Time: 33s | D_loss: 0.8553 | G_loss: 1.8133\n",
      "   * EPOCH 29 | Time: 34s | D_loss: 0.8509 | G_loss: 1.7620\n",
      "   * EPOCH 30 | Time: 36s | D_loss: 0.8404 | G_loss: 1.7780\n",
      "   * EPOCH 31 | Time: 36s | D_loss: 0.8364 | G_loss: 1.8251\n",
      "   * EPOCH 32 | Time: 37s | D_loss: 0.8342 | G_loss: 1.8113\n",
      "   * EPOCH 33 | Time: 38s | D_loss: 0.8368 | G_loss: 1.7801\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    z = torch.randn(mb_size, Z_dim)\n",
    "    samples = G(Variable(z)).data.numpy()[:16]\n",
    "    plot(samples, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
