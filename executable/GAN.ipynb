{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "intermediate_path = os.path.join(\"..\", \"intermediate\", \"gan\")\n",
    "if not os.path.exists(intermediate_path):\n",
    "    os.makedirs(intermediate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mb_size = 64\n",
    "epochs = 100\n",
    "Z_dim = 100\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]\n",
    "    xavier_stddev = 1. / np.sqrt((in_dim+out_dim) / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev,\n",
    "                    requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "Whx = xavier_init(size=[h_dim, X_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def G(z):\n",
    "    h = F.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = F.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = F.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    y = F.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    for p in params:\n",
    "        p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    mnist.MNIST('../data', train=True, download=True,\n",
    "                transform=transforms.ToTensor()),\n",
    "                batch_size=mb_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    start = time.time()\n",
    "    \n",
    "    for i, (X, _) in enumerate(train_loader):\n",
    "        ones_label = Variable(torch.ones(X.size(0)))\n",
    "        zeros_label = Variable(torch.zeros(X.size(0)))\n",
    "        X = X.view(-1, 784)\n",
    "        X = Variable(X)\n",
    "        # Sample data\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        \n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        D_loss_real = F.binary_cross_entropy(D_real, ones_label)\n",
    "        D_loss_fake = F.binary_cross_entropy(D_fake, zeros_label)\n",
    "        \n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        \n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "        reset_grad()\n",
    "        \n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        G_sample = G(z)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        G_loss = F.binary_cross_entropy(D_fake, ones_label)\n",
    "        \n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "        reset_grad()\n",
    "        \n",
    "        D_losses.add(D_loss.data.cpu()[0] * X.size(0), X.size(0))\n",
    "        G_losses.add(G_loss.data.cpu()[0] * X.size(0), X.size(0))\n",
    "        \n",
    "    print(\"   * EPOCH {} | Time: {}s | D_loss: {:.4f} | G_loss: {:.4f}\"\n",
    "          .format(epoch, round(time.time()-start),\n",
    "                  D_losses.value()[0],\n",
    "                  G_losses.value()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot(samples, epoch):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis(\"off\")\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "        plt.imshow(sample.reshape(28, 28), cmap=\"Greys_r\")\n",
    "\n",
    "    out_path = os.path.join(intermediate_path, \"out\")\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    out_filepath = os.path.join(out_path, \n",
    "                                \"{}.png\".format(str(epoch).zfill(3)))\n",
    "    plt.savefig(out_filepath, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   * EPOCH 1 | Time: 25s | D_loss: 0.0885 | G_loss: 5.3372\n",
      "   * EPOCH 2 | Time: 26s | D_loss: 0.0639 | G_loss: 5.1707\n",
      "   * EPOCH 3 | Time: 25s | D_loss: 0.1065 | G_loss: 4.5663\n",
      "   * EPOCH 4 | Time: 25s | D_loss: 0.2214 | G_loss: 4.6510\n",
      "   * EPOCH 5 | Time: 26s | D_loss: 0.3088 | G_loss: 4.1979\n",
      "   * EPOCH 6 | Time: 25s | D_loss: 0.4808 | G_loss: 3.7872\n",
      "   * EPOCH 7 | Time: 25s | D_loss: 0.5365 | G_loss: 3.1798\n",
      "   * EPOCH 8 | Time: 26s | D_loss: 0.5744 | G_loss: 3.1267\n",
      "   * EPOCH 9 | Time: 25s | D_loss: 0.6274 | G_loss: 2.9110\n",
      "   * EPOCH 10 | Time: 25s | D_loss: 0.6818 | G_loss: 2.7613\n",
      "   * EPOCH 11 | Time: 25s | D_loss: 0.6946 | G_loss: 2.6511\n",
      "   * EPOCH 12 | Time: 26s | D_loss: 0.7201 | G_loss: 2.7746\n",
      "   * EPOCH 13 | Time: 25s | D_loss: 0.7558 | G_loss: 2.6204\n",
      "   * EPOCH 14 | Time: 25s | D_loss: 0.7741 | G_loss: 2.3711\n",
      "   * EPOCH 15 | Time: 25s | D_loss: 0.7586 | G_loss: 2.2646\n",
      "   * EPOCH 16 | Time: 26s | D_loss: 0.7686 | G_loss: 2.1683\n",
      "   * EPOCH 17 | Time: 26s | D_loss: 0.7824 | G_loss: 2.1378\n",
      "   * EPOCH 18 | Time: 26s | D_loss: 0.7918 | G_loss: 2.1628\n",
      "   * EPOCH 19 | Time: 26s | D_loss: 0.7763 | G_loss: 2.0816\n",
      "   * EPOCH 20 | Time: 27s | D_loss: 0.8013 | G_loss: 1.9879\n",
      "   * EPOCH 21 | Time: 27s | D_loss: 0.8011 | G_loss: 2.0188\n",
      "   * EPOCH 22 | Time: 28s | D_loss: 0.8214 | G_loss: 1.9092\n",
      "   * EPOCH 23 | Time: 29s | D_loss: 0.8271 | G_loss: 1.9075\n",
      "   * EPOCH 24 | Time: 30s | D_loss: 0.8330 | G_loss: 1.8905\n",
      "   * EPOCH 25 | Time: 30s | D_loss: 0.8387 | G_loss: 1.8859\n",
      "   * EPOCH 26 | Time: 31s | D_loss: 0.8488 | G_loss: 1.7896\n",
      "   * EPOCH 27 | Time: 32s | D_loss: 0.8487 | G_loss: 1.8290\n",
      "   * EPOCH 28 | Time: 33s | D_loss: 0.8553 | G_loss: 1.8133\n",
      "   * EPOCH 29 | Time: 34s | D_loss: 0.8509 | G_loss: 1.7620\n",
      "   * EPOCH 30 | Time: 36s | D_loss: 0.8404 | G_loss: 1.7780\n",
      "   * EPOCH 31 | Time: 36s | D_loss: 0.8364 | G_loss: 1.8251\n",
      "   * EPOCH 32 | Time: 37s | D_loss: 0.8342 | G_loss: 1.8113\n",
      "   * EPOCH 33 | Time: 38s | D_loss: 0.8368 | G_loss: 1.7801\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    z = torch.randn(mb_size, Z_dim)\n",
    "    samples = G(Variable(z)).data.numpy()[:16]\n",
    "    plot(samples, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    \"data_path\": os.path.join(\"..\", \"data\"),\n",
    "    \"workers\": 5,\n",
    "    \"batch_size\": 64,\n",
    "    \"image_size\": 64,\n",
    "    \"z_dim\": 100,\n",
    "    \"G_features\": 64,\n",
    "    \"D_features\": 64,\n",
    "    \"image_channels\": 3,\n",
    "    \"epochs\": 25,\n",
    "    \"lr\": 0.0002,\n",
    "    \"beta1\": 0.5,\n",
    "    \"cuda\": True,\n",
    "    \"intermediate_path\": os.path.join(\"..\", \"intermediate\", \"dcgan\"),\n",
    "    \"seed\": 7\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.makedirs(args.intermediate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root=args.data_path, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Scale(args.image_size),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                  ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=args.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(args.z_dim, args.G_features * 8,\n",
    "                               4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(args.G_features * 8, args.G_features * 4,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(args.G_features * 4, args.G_features * 2,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(args.G_features * 2, args.G_features,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.G_features),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 16 x 16\n",
    "            nn.ConvTranspose2d(args.G_features, args.image_channels,\n",
    "                               4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_netG (\n",
       "  (main): Sequential (\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU (inplace)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU (inplace)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (8): ReLU (inplace)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (11): ReLU (inplace)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = _netG()\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 32 x 32\n",
    "            nn.Conv2d(args.image_channels, args.D_features,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 16 x 16\n",
    "            nn.Conv2d(args.D_features, args.D_features * 2,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 8 x 8\n",
    "            nn.Conv2d(args.D_features * 2, args.D_features * 4,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(args.D_features * 4, args.D_features * 8,\n",
    "                      4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(args.D_features * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(args.D_features * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_netD (\n",
       "  (main): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU (0.2, inplace)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (4): LeakyReLU (0.2, inplace)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (7): LeakyReLU (0.2, inplace)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (10): LeakyReLU (0.2, inplace)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = _netD()\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if args.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_optimizer = optim.Adam(netD.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999))\n",
    "G_optimizer = optim.Adam(netG.parameters(), lr=args.lr,\n",
    "                         betas=(args.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    D_real_accuracies = AverageValueMeter()\n",
    "    D_fake_accuracies = AverageValueMeter()\n",
    "    G_real_accuracies = AverageValueMeter()\n",
    "    \n",
    "    start = time.time()\n",
    "    for i, (real, _) in enumerate(data_loader):\n",
    "        batch_size = real.size(0)\n",
    "        real_label = Variable(torch.ones(batch_size))\n",
    "        fake_label = Variable(torch.zeros(batch_size))\n",
    "        real = Variable(real)\n",
    "        z = Variable(torch.randn(batch_size, args.z_dim, 1, 1))\n",
    "        if args.cuda:\n",
    "            real_label = real_label.cuda()\n",
    "            fake_label = fake_label.cuda()\n",
    "            real = real.cuda()\n",
    "            z = z.cuda()\n",
    "        \n",
    "        real_output = netD(real)\n",
    "        D_real_loss = criterion(real_output, real_label)\n",
    "        D_real_loss.backward()\n",
    "        D_real_accuracy = real_output.data.mean()\n",
    "        \n",
    "        fake = netG(z)\n",
    "        fake_output = netD(fake.detach())\n",
    "        D_fake_loss = criterion(fake_output, fake_label)\n",
    "        D_fake_loss.backward()\n",
    "        D_fake_accuracy = fake_output.data.mean()\n",
    "        \n",
    "        D_loss = (D_real_loss + D_fake_loss)/2\n",
    "        D_optimizer.step()\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        output = netD(fake)\n",
    "        G_loss = criterion(output, real_label)\n",
    "        G_loss.backward()\n",
    "        G_real_accuracy = output.data.mean()\n",
    "        G_optimizer.step()\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        D_losses.add(D_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        G_losses.add(G_loss.data.cpu()[0] * batch_size, batch_size)\n",
    "        D_real_accuracies.add(D_real_accuracy * batch_size, batch_size)\n",
    "        D_fake_accuracies.add(D_fake_accuracy * batch_size, batch_size)\n",
    "        G_real_accuracies.add(G_real_accuracy * batch_size, batch_size)\n",
    "        \n",
    "    print(\"=> EPOCH {:2d} | Time: {}s | D_loss: {:.3f} | G_loss: {:.3f} \"\n",
    "          \"| D_real_acc: {:.3f} | D_fake_acc: {:.3f} | G_real_acc: {:.3f}\"\n",
    "          .format(epoch, int(time.time()-start), D_losses.value()[0],\n",
    "                  G_losses.value()[0], D_real_accuracies.value()[0],\n",
    "                  D_fake_accuracies.value()[0], G_real_accuracies.value()[0]))\n",
    "    \n",
    "    z = Variable(torch.randn(args.batch_size, args.z_dim, 1, 1))\n",
    "    if args.cuda:\n",
    "        z = z.cuda()\n",
    "    fake = netG(z)\n",
    "    vutils.save_image(fake.data.cpu(), os.path.join(\n",
    "        args.intermediate_path,\n",
    "        \"fake_samples_epoch_{:02d}.png\".format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH  1 | Time: 175s | D_loss: 0.586 | G_loss: 0.749 | D_real_acc: 0.877 | D_fake_acc: 0.618 | G_real_acc: 0.503\n",
      "=> EPOCH  2 | Time: 175s | D_loss: 0.642 | G_loss: 0.577 | D_real_acc: 0.791 | D_fake_acc: 0.638 | G_real_acc: 0.569\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs+1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
